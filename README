# DataMetrics

Pushing metrics (gathered from API/Internet) to graphite, to make them visible in Grafana.

## Architecture

Current projects setup looks like that.
There are celery tasks running every minute (could be configured to something more/less often in `settings.py`)
Tasks are doing calls to APIs to gather info about crypto and stock prices, transform received data to `graphite` metrics format and do HTTP requests with metrics (in `json` format using BasictAuth) to graphite.

## Running manual ingestion locally

To run/test ingestion locally you need to install requires, make sure your environment has variables needed by this project and then run python run_once script. Run `python run_once -h` for help. Current project was tested with `python 3.8.5`

```bash
pip install -r requirements.txt
export REDIS_URL=<REDIS_URL>
export GRAPHITE_USER=<GRAPHANA_BASIC_AUTH_USER>
export GRAPHITE_PASSWORD=<GRAPHANA_BASIC_AUTH_PASSWORD>
export IEX_CLOUD_API_TOKEN=<IEX_CLOUD_API_TOKEN>

python run_once.py --crypto --stocks
```

## Running using heroku and celery

TODO

## Scalability:

### Storage 
Storing metrics is done on `graphite` side, so to support much bigger number of metrics/data you need to make sure your graphite have space to that. With my current setup using GrafanaLabs I can store up to 100GB of logs there before being charged more.., but it should automatically scale with more usage.

### Compute
Celery side is deployed on heroku. So simplest way of scaling up and make sure we have more compute for reading/parsing metrics gathered is to add dynos to your celery workers: `heroku ps:scale worker=more`.

For Graphite/Grafana similary if they are just hosted by GrafanaLabs they should scale (use more resources) with more traffic //TODO look for more details on that

### Specific questions

**How to support much larger of metrics?** From code perspective it should be easy to add new sources/metrics by either just updating `settings.py` or  adding new Celery tasks with different sources. If number of metrics we want to track is often changing, I think good idea would be to create relational database with those metrics and make it used by tasks so that deployment is not needed to add new metrics.

**What if you needed to sample them more frequently?** Celery can run more often than every minute and it's just part of settings to run more frequently. But of course there maybe some issues if we decide to run it every second etc, current limitation being using HTTP to get/send data. So here it's possible we would need to switch to different methods. 
https://graphite.readthedocs.io/en/latest/feeding-carbon.html#using-amqp

**Had many users accessing your dashboard to view metrics>** This is on Grafana side. Current plan support just 10 users so it obviously doesn't work with it. I read about people running grafana with 10,000 people TODO

## Monitoring:

In general Grafana is quite good tool for monitoring so I would most likely use that. More details below. Apart from that heroku also has some build in monitoring (for redis - used by Celery) and possibly add flower here: https://github.com/bsab/heroku-celery-monitor


**How would you track the health and uptime of your application**

 - As project is already using grafana, I would also add logger which would dump any http errors we receive from requests
 to livecoin feed, or grafana's graphite. There is service on graphana called Loki so would like to use this one.



